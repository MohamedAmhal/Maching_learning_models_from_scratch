{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "834a66f2-5cc1-4fa7-b6b8-b3ddd8564ebd",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6b009-5fec-4806-bd3e-c62d019d165c",
   "metadata": {},
   "source": [
    "In this lab we will implement a linear regression model with n variables (1 ==> n), we will use two libraries \n",
    "- numpy \n",
    "- matplotlib\n",
    "\n",
    "we should have also some basics in linear algebra (the dot product, implementing vectors, matrix, ...)\n",
    "let's get started !!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96fe13d-f443-43da-9738-4d1a97731d95",
   "metadata": {},
   "source": [
    "## The problem statement :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7464fb1-f467-4f1d-9e36-d04f75e11f1f",
   "metadata": {},
   "source": [
    "Imagine the data conteint 4 features (size, number of bedrooms, number of floors, the age of the house)\n",
    "\n",
    "so with all fo this features w'll predicte the price of the house !!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30431b-c930-4ce2-89e8-00d1365c7485",
   "metadata": {},
   "source": [
    "| Size(m3) | Number of bedrooms | Number of floors | Age of the house | Price in 1000 MAD |\n",
    "|-------------------------|--------------------|-----------------|------------------|---------------------|\n",
    "| 2104                    | 5                  | 1               | 45               | 460                 |\n",
    "| 1416                    | 3                  | 2               | 40               | 232                 |\n",
    "| 852                     | 2                  | 1               | 35               | 178                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608c143-87c6-4f3b-a19c-367d67d5b2a8",
   "metadata": {},
   "source": [
    "## Import the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f5bcca75-ba6c-4ef5-b898-425274676696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "63c0c9b7-c3ef-42f3-b2ac-8effcdb0d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[2104, 5, 1, 45],\n",
    "           [1416, 3, 2, 40],\n",
    "           [852, 2, 1, 35]])\n",
    "Y_train = np.array([460, 232, 178])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93eaed0c-c0aa-4781-903b-2c84e959d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "the number of examples : 3\n",
      "the number of features : 4\n",
      "The type of X_train is <class 'numpy.ndarray'>\n",
      "The type of Y_train is <class 'numpy.ndarray'>\n",
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      "[460 232 178]\n"
     ]
    }
   ],
   "source": [
    "# display the data :\n",
    "print(X_train.shape)\n",
    "print(f'the number of examples : {X_train.shape[0]}')\n",
    "print(f'the number of features : {X_train.shape[1]}')\n",
    "print(f'The type of X_train is {type(X_train)}')\n",
    "print(f'The type of Y_train is {type(Y_train)}')\n",
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b61ff-d133-44ed-bff8-87ed6892ab62",
   "metadata": {},
   "source": [
    "## The parameters :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368affcd-d767-42b7-93cb-6bc54be1aa72",
   "metadata": {},
   "source": [
    "### 1. the w parameter :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d4eba-c7cd-4400-a537-f413326e4773",
   "metadata": {},
   "source": [
    "To define the size of w , we need to determine the number of features , for example if we have 5 features so we need (w1, w2. w3, w4, w5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2f836-d8da-4826-83b8-26fd16f502e7",
   "metadata": {},
   "source": [
    "so m : the number of features in the problem statement w ==> (m, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "46c585ce-7d67-4ade-a940-ac663fc1bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the m and n (the number of examples):\n",
    "n = X_train.shape[0]\n",
    "m = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a045eb-2539-4b6b-bbdf-aa495529529e",
   "metadata": {},
   "source": [
    "### 2. The b parameter :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a48bcf-528d-421e-b50d-805dff50586d",
   "metadata": {},
   "source": [
    "the b is one value , (the one scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "40c07253-6fea-4489-a7ea-24e32fc2a8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape is (4,)\n",
      "and b shape is <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#examples\n",
    "w_init = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "b_init = 785.1811367994083\n",
    "print(f'W shape is {w_init.shape}\\nand b shape is {type(b_init)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd5ed0-5a49-4bbb-b502-93803871eceb",
   "metadata": {},
   "source": [
    "## Making a function that predict the price :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45641b3-f7e2-4074-8307-193e0fb399e3",
   "metadata": {},
   "source": [
    "we have the linear function : f(X) = (W1 * X[0]    +    W2 * X[1]    + ... +    Wn * X[n - 1])    + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884cb3c5-b3ae-4ec1-89b1-49a6dcf4dc48",
   "metadata": {},
   "source": [
    "OR   f(X) = W.X + b    Where w and b are verctors    and . is the dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba0ef0b-801a-4d7f-9a35-6518ca3ed314",
   "metadata": {},
   "source": [
    "### Implementation of the function :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe241bf7-7d00-4cf9-9e1a-e7984e28023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_loop(X, W, b):\n",
    "    '''\n",
    "    X : the data \n",
    "    W : the first parameter of f \n",
    "    b : the second parameter of f\n",
    "    return : the prediction \n",
    "    '''\n",
    "    prediction = X.dot(W) + b\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24e0b98d-644e-46db-a8de-b0318636fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "459.9999976194082\n"
     ]
    }
   ],
   "source": [
    "# some examples\n",
    "x = np.array([[2104, 5, 1, 45]])\n",
    "print(x.shape)\n",
    "print(prediction_loop(x, w_init, b_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45936d63-b2e6-4787-b468-016afa21c796",
   "metadata": {},
   "source": [
    "## calculate the cost function :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "22c69080-dda8-4b39-b907-e5c2b0044741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function :\n",
    "def cost_function(X, Y, W, b):\n",
    "    '''\n",
    "    X: the data without the target varaible\n",
    "    Y: the target varaible\n",
    "    W: the prameter (vector !)\n",
    "    b: the second parameter \n",
    "    return: the cost !\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    cost = 0\n",
    "    for i in range(n):\n",
    "        cost += ((X[i].dot(W) + b) - Y[i]) ** 2\n",
    "\n",
    "    cost *= (1/(2*n))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e85eef87-4c5a-465d-b9fd-ccc5d3edb30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5578904330213735e-12\n",
      "459.9999976194082\n",
      "-------------------------------------\n",
      "2.3786825199276525\n",
      "457.81886081999994\n",
      "-------------------------------------\n",
      "7.291851679927477\n",
      "463.81886081999994\n"
     ]
    }
   ],
   "source": [
    "# some exmples\n",
    "print(cost_function(X_train, Y_train, w_init,b_init))\n",
    "print(prediction_loop(x, w_init, b_init))\n",
    "print('-------------------------------------')\n",
    "w = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "b = 783\n",
    "print(cost_function(X_train, Y_train, w, b))\n",
    "print(prediction_loop(x, w, b))\n",
    "print('-------------------------------------')\n",
    "w1 = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "b1 = 789\n",
    "print(cost_function(X_train, Y_train, w1, b1))\n",
    "print(prediction_loop(x, w1, b1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d53e9-4aaf-4f13-bded-eacaa24fabce",
   "metadata": {},
   "source": [
    "## Gradient descente multi variable (compute the partial derivate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd92c0-1421-4ece-9196-9c1a910e6f14",
   "metadata": {},
   "source": [
    "the algorithm is also the same thing compared with one variable , w'll add the partial derivates of f  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1442dcc-5cd3-4453-b367-4fe0a1fe840e",
   "metadata": {},
   "source": [
    "we will start with calculating the partail derivates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c144c47f-5c0f-4b30-b1c3-902215871b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, Y, W, b):\n",
    "    '''\n",
    "    X : the data without target variable\n",
    "    Y : the data related to the target varaible\n",
    "    W : the first vector parameter\n",
    "    b : the second parameter \n",
    "    return :\n",
    "           a list that conteint the partial DR\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    dj_w = np.zeros((m,))\n",
    "    dj_b = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            dj_w[j] += (1/ n) * (((X[i].dot(W) + b) - Y[i]) * X[i][j])\n",
    "        dj_b += (1/n) * ((X[i].dot(W) + b) - Y[i])\n",
    "\n",
    "    return dj_w, dj_b\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828c721-de59-468a-9e94-885828d9c156",
   "metadata": {},
   "source": [
    "## Gradient descente :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8708be-fb6b-4046-a465-8c9b407990e9",
   "metadata": {},
   "source": [
    "we will now implement the algo of bach gradient descente(par lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2fc48156-0656-4140-9aca-f615d18cab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a170a36-c32d-4372-9120-e9b8aee0773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, w_in, b_in, alpha, num_iter, compute_gradient, cost_function):\n",
    "    '''\n",
    "    X: the data without target varaible\n",
    "    Y: the data related to the target varaible\n",
    "    w_in : the first parameter initialisation\n",
    "    b_in : the seconde parameter initialisation\n",
    "    alpha : the rate learning \n",
    "    num_iter : the number of itertions in the algo\n",
    "    compute_gradient : the function that calculate the partial derivations\n",
    "    const_function : the function that calculate the cost of each parameters\n",
    "    return :\n",
    "            the best parameters that optimazing the cost function (the same thing of one variable !!)\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    j_histo = []\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        dj_w, dj_b = compute_gradient(X, Y, w, b)\n",
    "\n",
    "        w = w - alpha * (dj_w)\n",
    "        b = b - alpha * (dj_b)\n",
    "\n",
    "        j_histo.append(cost_function(X, Y, w, b))\n",
    "\n",
    "\n",
    "        if i % (math.ceil(num_iter / 10)) == 0 :\n",
    "            print(f\"Iteration {i:4d}: Cost {j_histo[-1]:8.2f} \")\n",
    "\n",
    "    return w, b, j_histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6431fe9f-dc85-449c-a140-262f5e08cd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  2529.46 \n",
      "Iteration  100: Cost   695.99 \n",
      "Iteration  200: Cost   694.92 \n",
      "Iteration  300: Cost   693.86 \n",
      "Iteration  400: Cost   692.81 \n",
      "Iteration  500: Cost   691.77 \n",
      "Iteration  600: Cost   690.73 \n",
      "Iteration  700: Cost   689.71 \n",
      "Iteration  800: Cost   688.70 \n",
      "Iteration  900: Cost   687.69 \n",
      "b,w found by gradient descent: -0.00,[ 0.20396569  0.00374919 -0.0112487  -0.0658614 ] \n"
     ]
    }
   ],
   "source": [
    "# some examlpes :\n",
    "w_in = np.zeros_like(w_init)\n",
    "b_in = 0\n",
    "iteration = 1000\n",
    "alpha = 5.0e-7\n",
    "w_f, b_f, j_final = gradient_descent(X_train, Y_train, w_in, b_in, alpha, iteration, compute_gradient, cost_function)\n",
    "print(f\"b,w found by gradient descent: {b_f:0.2f},{w_f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b01a75a0-b5e9-420c-a38b-45cd6dfbbf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict value :  426.18530497189204 target varaible : 460\n",
      "-------------------------------------\n",
      "predict value :  286.1674720078562 target varaible : 232\n",
      "-------------------------------------\n",
      "predict value :  171.46763087132317 target varaible : 178\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# doing some prediction\n",
    "x = np.array([[2104, 5, 1, 45]])\n",
    "print('predict value : ', prediction_loop(x, w_f, b_f), 'target varaible :', Y_train[0])\n",
    "print('-------------------------------------')\n",
    "x1 = np.array([[1416, 3, 2, 40]])\n",
    "print('predict value : ', prediction_loop(x1, w_f, b_f), 'target varaible :', Y_train[1])\n",
    "print('-------------------------------------')\n",
    "x2 = np.array([[852, 2, 1, 35]])\n",
    "print('predict value : ', prediction_loop(x2, w_f, b_f), 'target varaible :', Y_train[2])\n",
    "print('-------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a72037-1b7f-4a09-8c13-39d57aa1c6d9",
   "metadata": {},
   "source": [
    "## Building the model regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1c7a1771-8256-4826-bd83-691b0ae5baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self, learning_rate=0.01, iteration=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration = iteration\n",
    "        self.omega = None\n",
    "        self.cost_histor = []\n",
    "\n",
    "\n",
    "    def iniatlise_parameter(self, n):\n",
    "        self.omega = np.zeros(n)\n",
    "        self.bais = 0\n",
    "\n",
    "\n",
    "    def cost_function(self, X, Y):\n",
    "        '''\n",
    "        X: the data without the target varaible\n",
    "        Y: the target varaible\n",
    "        return: the cost !\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        m = X.shape[1]\n",
    "        cost = 0\n",
    "        for i in range(n):\n",
    "            cost += ((X[i].dot(self.omega) + self.bais) - Y[i]) ** 2\n",
    "    \n",
    "        cost *= (1/(2*n))\n",
    "        return cost\n",
    "\n",
    "\n",
    "    def compute_gradient(self, X, Y):\n",
    "        '''\n",
    "        X : the data without target variable\n",
    "        Y : the data related to the target varaible\n",
    "        return :\n",
    "               a list that conteint the partial DR\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        m = X.shape[1]\n",
    "        dj_w = np.zeros(m)\n",
    "        dj_b = 0\n",
    "    \n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                dj_w[j] += (1/ n) * (((X[i].dot(self.omega) + self.bais) - Y[i]) * X[i][j])\n",
    "            dj_b += (1/n) * ((X[i].dot(self.omega) + self.bais) - Y[i])\n",
    "    \n",
    "        return dj_w, dj_b\n",
    "\n",
    "\n",
    "    def gradient_descent(self, X, Y):\n",
    "        '''\n",
    "        X: the data without target varaible\n",
    "        Y: the data related to the target varaible\n",
    "        return :\n",
    "                nothing (some changes)\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        m = X.shape[1]\n",
    "        for i in range(self.iteration):\n",
    "            dj_w, dj_b = self.compute_gradient(X, Y)\n",
    "    \n",
    "            self.omega = self.omega - self.learning_rate * (dj_w)\n",
    "            self.bais = self.bais - self.learning_rate * (dj_b)\n",
    "    \n",
    "            self.cost_histor.append(self.cost_function(X, Y))\n",
    "    \n",
    "    \n",
    "            #if i % (math.ceil(self.iteration / 10)) == 0 :\n",
    "                #print(f\"Iteration {i:4d}: Cost {self.cost_histor} \")\n",
    "\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        '''\n",
    "        X: the data without target varaible\n",
    "        Y: the data related to the target varaible\n",
    "        return :\n",
    "                nothing (just fiting the model)\n",
    "        '''\n",
    "\n",
    "        # initialize the parameters\n",
    "        self.iniatlise_parameter(X.shape[1])\n",
    "\n",
    "        #run the gradient descent\n",
    "        self.gradient_descent(X, Y)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        X :  the data\n",
    "        return : the prediction\n",
    "        '''\n",
    "        return X.dot(self.omega) + self.bais\n",
    "\n",
    "\n",
    "    def MSE(self, y_true, y_predict):\n",
    "        '''\n",
    "        y_true : the values in target variable\n",
    "        y_predict : the values in the prediction\n",
    "        '''\n",
    "\n",
    "        return np.mean((y_true - y_predict) ** 2)\n",
    "\n",
    "\n",
    "    def R2_score(self, y_true, y_predict):\n",
    "        '''\n",
    "        y_true : the values in target variable\n",
    "        y_predict : the values in the prediction\n",
    "        '''\n",
    "        mean_y_true = np.mean(y_true)\n",
    "        ss_tot = np.sum((y_true - mean_y_true) ** 2)\n",
    "        ss_res = np.sum((y_true - y_predict) ** 2)\n",
    "\n",
    "        return (1 - (ss_res / ss_tot))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028303d6-1d46-4652-9c8a-435567a4fdd9",
   "metadata": {},
   "source": [
    "### Examples : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c850cc0-0bb2-4a6d-bd07-e40bfb104e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2104\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "abfae7b2-5a4d-4ad7-86f5-6d15c441d111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [426.18530497 286.16747201 171.46763087]\n",
      "MSE: 1373.406823333041\n",
      "R² Score: 0.908047213220873\n"
     ]
    }
   ],
   "source": [
    "# create the class\n",
    "model = LinearRegression(5.0e-7, 1000)\n",
    "\n",
    "# fiting the model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# make prediction \n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "## Check predictions\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "## Evaluate the model\n",
    "MSE = model.MSE(Y_train, predictions)\n",
    "R2 = model.R2_score(Y_train, predictions)\n",
    "\n",
    "print(\"MSE:\", MSE)\n",
    "print(\"R² Score:\", R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9c9ef-82e8-4993-8039-2a2641e8a1ee",
   "metadata": {},
   "source": [
    "## Upgrading "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7f1f5-27c1-4124-b42a-949658bea673",
   "metadata": {},
   "source": [
    "......................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de744e-920b-459f-92ab-c51f48993c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
